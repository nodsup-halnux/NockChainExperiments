Finding all comments in files, for directory ./nockchain-postlaunch-revised/hoon/common/ztd


## eight.hoon
- Line 1: :: Summary of file:
- Line 2: :: I. Core Data Types and Structures
- Line 3: :: +constraint-degrees, +constraint-data, +constraints:
- Line 4: ::   Define how computational constraints are structured per table—
- Line 5: ::   grouped by type (boundary, row, transition, terminal, extra)
- Line 6: ::   with associated polynomial degrees.
- Line 7: ::
- Line 8: :: +preprocess-0:
- Line 9: ::   Encapsulates per-table constraint metadata, enabling reuse across proofs.
- Line 10: ::
- Line 11: :: +stark-config, +stark-input:
- Line 12: ::   Define global parameters such as expansion factor and security level,
- Line 13: ::   along with computation-independent verifier input.

- Line 15: :: II. Prover Infrastructure and Polynomial Management
- Line 16: :: ++compute-codeword-commitments:
- Line 17: ::   Central routine transforming trace columns into polynomial commitments.
- Line 18: ::   Includes interpolation (compute-table-polys),
- Line 19: ::   low-degree extension (compute-lde),
- Line 20: ::   and Merkle tree commitment (bp-build-merk-heap).
- Line 21: ::
- Line 22: :: compute-table-polys:
- Line 23: ::   Interpolates each table column into a low-degree polynomial over the trace domain.
- Line 24: ::
- Line 25: :: compute-lde:
- Line 26: ::   Extends these polynomials to a larger evaluation domain,
- Line 27: ::   suitable for FRI-based low-degree testing and proof generation.

- Line 29: :: III. Degree Analysis and Constraint Handling
- Line 30: :: ++degree-processing:
- Line 31: ::   Computes the degree bounds of constraint polynomials for each table,
- Line 32: ::   adjusting for trace length and type (boundary, row, etc.).
- Line 33: ::
- Line 34: :: +constraints-w-deg:
- Line 35: ::   Holds constraints annotated with their effective degrees,
- Line 36: ::   essential for determining valid bounds and ensuring protocol soundness.

- Line 38: :: IV. Composition Polynomial Generation
- Line 39: :: ++compute-composition-poly, ++do-compute-composition-poly:
- Line 40: ::   Construct the full composition polynomial from trace and constraint inputs.
- Line 41: ::   Applies zerofiers to enforce boundary and transition conditions,
- Line 42: ::   aggregates constraint evaluations using arithmetic over bpolys.
- Line 43: ::
- Line 44: :: Constructs like bpadd, bpdiv combine scaled constraint terms efficiently,
- Line 45: ::   maintaining the degree bound needed for STARK verification.
- Line 46: :: If `is-extra` is false, skip the following computation and return `zero-bpoly`.
- Line 47: :: Otherwise, compute the contribution of the `extra` constraints to the composition polynomial.
- Line 48: :: Divide by the row zerofier polynomial to normalize domain alignment.
- Line 49: :: Call `process-composition-constraints` to evaluate each extra constraint polynomial.
- Line 50: :: Constraints are weighted using challenges (alpha, beta) extracted from `chals`.
- Line 51: :: Challenge indices begin after boundary, row, transition, and terminal constraint counts.
- Line 52: ::
- Line 53: :: ++process-composition-constraints:
- Line 54: :: Processes a list of constraints paired with degree annotations and mp-ultra definitions.
- Line 55: :: For each constraint:
- Line 56: ::   - Substitutes in the trace and dynamic values into the mp expression to generate a composition polynomial.
- Line 57: ::   - Retrieves two weights: alpha and beta from the weights array.
- Line 58: ::   - Constructs a term of the form `p(x) * (α·X^{D−D_j} + β)` to lift the polynomial to uniform degree D−1.
- Line 59: ::   - Accumulates the resulting polynomial contribution into the composition polynomial using `bpadd`.

- Line 61: :: ++compute-deep:
- Line 62: :: Computes the DEEP composition polynomial used in STARK proof opening.
- Line 63: :: For each trace polynomial:
- Line 64: ::   - Converts it into field-based (fpoly) form.
- Line 65: ::   - Evaluates f(x) at two shifted points: Z and g·Z, computing `(f(x) - f(Z))/(x - Z)` and similar for gZ.
- Line 66: ::   - Forms a weighted linear combination of these evaluations using challenges and precomputed weights.
- Line 67: :: This is done twice: once using `deep-challenge` and once using `comp-eval-point`, then the two are added.
- Line 68: :: Additional composition pieces are incorporated similarly and summed with the trace contributions.

- Line 70: :: ++weighted-linear-combo:
- Line 71: :: Constructs a linear combination over rational expressions of the form `(f(x) - f(z)) / (x - z)`
- Line 72: :: where each term is scaled by a weight.
- Line 73: :: Each polynomial in the input list is offset by its corresponding opening value and normalized.
- Line 74: :: The total is accumulated using field additions and multiplications.

- Line 76: :: ++precompute-ntts:
- Line 77: :: Precomputes FFT-based NTT (Number Theoretic Transform) encodings of a set of polynomials.
- Line 78: :: Extends each polynomial to a specified length and computes its FFT over the target domain.
- Line 79: :: Returns a list of all such transformed polynomials, combined using `weld` for merging.

- Line 81: :: ++noun-get-zero-mults:
- Line 82: :: Computes how often a given noun appears in the "zero" table.
- Line 83: :: Used for determining multiplicity factors in exponent tables and external multipliers.
- Line 84: :: Operates by analyzing tree structures representing data paths (axes) in a nock formula tree.
- Line 85: :: Applies breadth-first transformations to align logical paths with computational representations.
- Line 86: :: Updates a map of subtree multiplicities using the `put-tree` arm to accumulate counts.

- Line 88: :: ++fink:
- Line 89: :: The core interpreter that traverses a nock formula in depth-first order.
- Line 90: :: Annotates each node with its axis (a breadth-first encoding of tree position).
- Line 91: :: Sorts formula nodes by axis to prepare for breadth-first evaluation in compute tables.
- Line 92: :: Builds a queue of evaluations and computes "extra data" per opcode.
- Line 93: :: Generates structures like `formula-data` and `interpret-data` to facilitate compilation.

- Line 95: :: ++interpret:
- Line 96: :: The recursive arm used by `fink` to evaluate a nock formula.
- Line 97: :: Handles each nock opcode (e.g., %0, %1, %2...) by applying the corresponding transformation.
- Line 98: :: Tags each step with its axis, captures zeroes and decode information,
- Line 99: :: and constructs a trace of intermediate computations and subformula products.
- Line 100: :: Implements ternary axis encoding to support nock’s structure (e.g., three subformulas in `%2`).
- Line 101: :: ++edit:
- Line 102: ::   Edits a noun tree at a given axis. If axis is 1, returns the new value.
- Line 103: ::   Otherwise, recursively navigates the tree based on the axis and modifies the relevant branch.
- Line 104: ::   Uses axis decoding (cap/mas) and pattern matches to update either the head (%2) or tail (%3).

- Line 106: :: ++record-all:
- Line 107: ::   Records multiple zero substitutions in a zero-map structure.
- Line 108: ::   Rolls over a list of `[subject, axis, new-subject]` triples and records each using `record`.

- Line 110: :: ++record:
- Line 111: ::   Records a single zero substitution in a nested map structure.
- Line 112: ::   If the entry does not exist, it initializes it.
- Line 113: ::   If it does exist, it increments the multiplicity count.

- Line 115: :: ++record-cons:
- Line 116: ::   Records a decode entry for a formula in a decode map.
- Line 117: ::   Uses the key `[formula head tail]` and increments count.

- Line 119: :: ++frag:
- Line 120: ::   Extracts a part of a noun at a given axis.
- Line 121: ::   Delegates to `frag-atom` if axis is atomic; otherwise, fails gracefully.

- Line 123: :: ++frag-atom:
- Line 124: ::   Atom-specific fragment logic.
- Line 125: ::   Navigates down the noun tree according to the axis.
- Line 126: ::   Recursively selects head (%2) or tail (%3) until reaching axis 1.

- Line 128: :: ++puzzle-nock:
- Line 129: ::   Constructs a proof-of-work "puzzle" from a block commitment and nonce.
- Line 130: ::   Absorbs both into a sponge function, produces random belts, generates a tree and a nock formula.
- Line 131: ::   Returns the subject and the generated formula.

- Line 133: :: ++powork:
- Line 134: ::   Produces a synthetic nock formula for a given proof-of-work length.
- Line 135: ::   Uses opcode `%6` with a combination of opcodes `%3` and `%0`.

- Line 137: :: ++gen-tree:
- Line 138: ::   Builds a binary tree from a list of atoms.
- Line 139: ::   Splits recursively to maintain a balanced shape.

- Line 141: :: ++stark-engine-jet-hook:
- Line 142: ::   Dummy hook to enable jet support in `lib/stark/prover.hoon`.
- Line 143: ::   Required for proper runtime behavior of jetted code.

- Line 145: :: ++stark-engine:
- Line 146: ::   Top-level configuration and calculator core for STARK parameters.
- Line 147: ::   Includes cryptographic constants, domain sizes, and constraint degree analysis.

- Line 149: :: ++num-challenges:
- Line 150: ::   Returns the number of challenges used, defined by `num-chals:chal`.

- Line 152: :: ++expand-factor:
- Line 153: ::   Calculates the domain expansion factor as a power of two.

- Line 155: :: ++num-spot-checks:
- Line 156: ::   Determines number of FRI verifier queries per round.

- Line 158: :: ++generator:
- Line 159: ::   Constant used as the field generator (7).

- Line 161: :: ++fri-folding-deg:
- Line 162: ::   Degree of folding per FRI round, must be a power of 2 (e.g., 8).

- Line 164: :: ++calc:
- Line 165: ::   Computes all STARK setup parameters from input table heights and constraint degree map.

- Line 167: :: ++omega:
- Line 168: ::   Computes the ordered root of unity for FRI domains.

- Line 170: :: ++fri-domain-len:
- Line 171: ::   Computes the full domain size as max padded trace length × expansion factor.

- Line 173: :: ++fri:
- Line 174: ::   Packages all FRI parameters into a single structure.

- Line 176: :: ++max-constraint-degree:
- Line 177: ::   Extracts the largest degree among all constraint types from a constraint-degrees struct.

- Line 179: :: ++max-degree / ++do-max-degree:
- Line 180: ::   Compute

- Line 189: ::    stark-core

- Line 192: ::  $zerofier-cache: cache from table height -> zerofier

- Line 194: ::  $table-to-constraint-degree: a map from table number to maximum constraint degree for that table

- Line 196: ::  mp-ultra constraint along with corresponding degrees of the constraints inside

- Line 198: ::  all constraints for one table

- Line 206: ::  constraint types
- Line 216: ::
- Line 217: ::  $preprocess-0: preprocess with a version tag attached

- Line 224: ::
- Line 225: ::  $stark-config: prover+verifier parameters unrelated to a particular computation
- Line 226: ::  Pin log factor and sec level to head.

- Line 231: ::TODO this type could potentially be improved

- Line 239: ::

- Line 258: ::

- Line 260: ::  +t-order: order terms (table names) by <=, except %jute table is always last

- Line 267: ::
- Line 268: ::  +td-order: order table-dats using +t-order

- Line 273: ::
- Line 274: ::  +tg-order: general ordering arm for lists with head given by table name

- Line 279: ::
- Line 280: ::
- Line 281: ::    jetted functions used by the stark prover

- Line 288: ::

- Line 313: ::
- Line 314: :: interpolate polynomials through table columns

-
- Line 350: ::
- Line 351: ::  the @ is a degree upper bound D_j of the associated composition
- Line 352: ::  codeword, and thereby dependent on trace length, i.e.
- Line 353: ::  deg(mp constraint)*(trace-len - 1) - deg(zerofier)

- Line 361: ::
- Line 362: ::  fri-deg-bound is D-1, where D is the next power of 2 greater than
- Line 363: ::  the degree bounds of all composition codewords

- 
- Line 596: ::
- Line 597: :: compute the DEEP Composition Polynomial

- Line 690: ::
- Line 691: ::  +precompute-ntts
- Line 692: ::
- Line
- Line 711: ::    fock-core

- Line 1076: ::
- Line 1077: ::  +puzzle-nock: powork puzzle

- Line 1119: ::    stark-engine

- Line 1121: ::
- Line 1122: ::  This is a dummy arm which is only here so lib/stark/prover.hoon can use it as its parent core.
- Line 1123: ::  Without it, jets won't work in that file.

- Line 1128: ::
